{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW8ezafytboj"
   },
   "source": [
    "In this notebook, you will\n",
    "\n",
    "- build on your existing knowledge of PyTorch and deep learning basics\n",
    "- prior knowledge of reinforcement learning is helpful but not required\n",
    "- \n",
    "\n",
    "\n",
    "Focus on\n",
    "- easy to understand, incremental steps vs. mathematical rigor\n",
    "- simplify (without trivializing) the algorithms when possible\n",
    "- narrow slice of reinforcement learning\n",
    "\n",
    "For a more mathematical treatment of reinforcement learning, policy gradients, and proximal policy optimization, check out:\n",
    "\n",
    "- [Sutton & Barto, \"Reinforcement Learning: An Introduction\"](http://incompleteideas.net/book/the-book-2nd.html) — the classic RL textbook, especially Chapters 13 and 14 for policy gradient methods\n",
    "- [OpenAI Spinning Up: Policy Gradient Methods](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#policy-gradient-methods) — practical and mathematical overview\n",
    "- [Proximal Policy Optimization Algorithms (Schulman et al., 2017)](https://arxiv.org/abs/1707.06347) — original PPO paper\n",
    "- [Lil'Log: Proximal Policy Optimization Explained](https://lilianweng.github.io/posts/2018-06-24-policy-gradient/#ppo) — blog post with clear math and diagrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, let's make sure you have the correct version of PyTorch installed. If you have an older version or want to start fresh, you can uninstall the current PyTorch, torchvision, and torchaudio packages using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ppfNl-aE8O3"
   },
   "outputs": [],
   "source": [
    "# !pip3 uninstall -y torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to install PyTorch with CUDA support (for GPU acceleration), you can use the following command. Make sure your environment supports CUDA 11.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8B8SEzrFC0T"
   },
   "outputs": [],
   "source": [
    "# !pip3 install torch --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import PyTorch and check the version to make sure everything is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "pt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up the device for computation. We'll use the GPU if it's available, otherwise we'll fall back to the CPU. The `nvidia-smi` command will show you information about your GPU if one is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "!nvidia-smi\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a dataset of names for our experiments. Let's fetch a list of names from GitHub using Python's `urllib` library. This will give us a simple, real-world dataset to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "with urllib.request.urlopen('https://raw.githubusercontent.com/karpathy/makemore/master/names.txt') as resp:\n",
    "  src = resp.read().decode('utf-8')\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's convert the downloaded text into a Python list of names. We'll take a quick look at the first few names to make sure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = src.splitlines()\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll extract the unique characters (tokens) used in the dataset. We'll also add special tokens for the start (`_`) and end (`.`) of a name. This will help us later when we encode and decode names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = \"_\" + \".\" + \"\".join(sorted(set(\"\".join(names))))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with our tokens, we'll create two dictionaries: `stoi` (string-to-index) and `itos` (index-to-string). These will let us easily convert between characters and their corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQTK1KWVA2Bw"
   },
   "outputs": [],
   "source": [
    "stoi = {v:k for k,v in enumerate(tokens)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdNYBWHNA3Qu",
    "outputId": "ca117f34-ba50-435c-cdf2-d6ef1d9f0e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '.': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n"
     ]
    }
   ],
   "source": [
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBl34iTVA7Q3"
   },
   "outputs": [],
   "source": [
    "itos = {k:v for k,v in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3D9YzGtpl0iV",
    "outputId": "22dae6f2-ba15-4f4a-f71d-0ad78e20893a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '.', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define two simple functions: `enc` to encode a name as a list of indices, and `dec` to decode a list of indices back to a string. This will make it easy to switch between string and numeric representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDHc4TkeoPZR"
   },
   "outputs": [],
   "source": [
    "enc = lambda name: [stoi[s] for s in name]\n",
    "dec = lambda chars: \"\".join(itos[i] for i in chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "YCr2w0ymA9_5",
    "outputId": "e4275234-e058-48bd-8ba8-ce469b347885"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'_emma.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec(enc('_emma.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a function `stot` that converts a string into a one-hot encoded tensor. This will be useful for representing names in a format suitable for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcFnwzhzoAA8"
   },
   "outputs": [],
   "source": [
    "stot = lambda name: pt.nn.functional.one_hot(pt.tensor(enc(name)), len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYAmJZJzBtJ9",
    "outputId": "dba9133d-cdab-4362-929a-1913cc4ea315"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stot('_emma.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go back from a one-hot encoded tensor to a string, we'll define the `ttos` function. This will help us interpret the outputs of our model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgIHff7OBr8t"
   },
   "outputs": [],
   "source": [
    "ttos = lambda x: dec(x.argmax(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "m8_DOTvzBcP_",
    "outputId": "43d53451-c242-4e8a-b200-acd8c98197d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'_emma.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttos(stot('_emma.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a constant `CTX_SZ` to represent a window size used by the model to predict the next character. For example, in a name `olivia`, the window \n",
    "- `oliv` predicts the token `i`\n",
    "- `livi` predicts the token `a`\n",
    "- `CTX_SZ` start of name tokens, i.e. `____` predict the token `o`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fKXBEDvimiC",
    "outputId": "32dcdd7d-87b3-47d9-8302-b83f4d39138c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTX_SZ = 4\n",
    "CTX_SZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `CTX_SZ` constant defined, you can illustrate how a name like `emma` is represented using the sparse embedding with `stot`.\n",
    "\n",
    "Create a tensor called `name` using the `CTX_SZ` start tokens `_` and a single end token`.` Also, report on the shape of the `name` tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "_mUtOTuzU0ui",
    "outputId": "8e953559-43b3-4959-b513-4ed12b740fd5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1003f4bcf4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCTX_SZ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"emma\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stot' is not defined"
     ]
    }
   ],
   "source": [
    "name = stot(\"\".join(CTX_SZ * \"_\" + \"emma\" + \".\"))\n",
    "name, name.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook will depart from common machine learning terminology to make the upcoming use of reinforcement learning easier to understand. The notebook will use the term **observations** to describe the inputs to the machine learning model (aka `X` or `obs`) while the outputs of the model will be described as **actions** (aka `y`). You are probably comfortable with the idea of training your machine learning model on `(X,y)` pairs, so the following will use the `(obs, action)` pairs. You can think of the action as the token that the model predicts as its output. Hence, generating the name is like making a series of actions to pick the right tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has a convenient `unfold` function to take a tensor like `name` and convert it to a sequence of observations, each with a window length of `CTX_SZ`. For example, you can `unfold` the `name` tensor along the first (0th) dimension using the step size of 1. For convenience, permute the shape of the resulting tensor to swap the last two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmUVF8-RYXOw",
    "outputId": "76f5b296-068c-449a-b4da-af41dd062b9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.unfold(0, CTX_SZ, 1).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the output of the `unfold` clearer you can use `ttos` to change the tensors back to string. For a name like `emma` you should get observations like\n",
    "\n",
    "- `___e`\n",
    "- `__em`\n",
    "- `_emm`\n",
    "- etc\n",
    "\n",
    "**NOTE:** Don't forget to drop the last token `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7MmUYaVZGDz",
    "outputId": "9b0a7a5f-8478-4767-d8cf-670578eed6bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['____', '___e', '__em', '_emm', 'emma']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ttos(x) for x in name.unfold(0, CTX_SZ, 1)[:-1, :, :].permute(0, 2, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you are going to need to `unfold` all of the names in the data set, create a function `name_to_obs` that implements this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnWYcvtomWX6"
   },
   "outputs": [],
   "source": [
    "name_to_obs = lambda name: stot(name).unfold(0, CTX_SZ, 1)[:-1, :, :].permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqS9Fp75aI01",
    "outputId": "f87fb79a-0cb2-4a12-ede5-ab97b2b76b13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_obs('____emma.').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create another function `name_to_action` that converts a name to all the action (i.e. output tokens) that should be predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cw53VPPlkNE8"
   },
   "outputs": [],
   "source": [
    "name_to_action = lambda name: stot(name)[CTX_SZ:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TBOmV1bak8A",
    "outputId": "a031355f-1924-44fb-f6db-d5ccd4dfa28d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = name_to_action('____emma.')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "Oobqlk5Ia3Ck",
    "outputId": "9ca1ce9e-acd6-4e78-ec9d-27d4d040ebe2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'emma.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttos(name_to_action('____emma.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to create the data set to train your model. \n",
    "\n",
    "- convert all the names in `names` to the observations\n",
    "- use `cat` to concatenate all the sparse embeddings of the names to a data set tensor `X_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOpQbiIW4C2V"
   },
   "outputs": [],
   "source": [
    "X_data = [name_to_obs(CTX_SZ * \"_\" + name + \".\") for name in names]\n",
    "X_data = pt.cat(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqsTZ8mK4I_A",
    "outputId": "1ce893ed-00db-4567-814a-621b93e1bc22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['____',\n",
       "  '___e',\n",
       "  '__em',\n",
       "  '_emm',\n",
       "  'emma',\n",
       "  '____',\n",
       "  '___o',\n",
       "  '__ol',\n",
       "  '_oli',\n",
       "  'oliv'],\n",
       " torch.Size([228146, 4, 28]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ttos(x) for x in X_data[:10]], X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the `X_data` tensor to your `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qG5ZsfTAnFfh"
   },
   "outputs": [],
   "source": [
    "X_data = X_data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the `y_data` tensor using `name_to_action` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66aF6A1zlMvz"
   },
   "outputs": [],
   "source": [
    "y_data = pt.cat([name_to_action(CTX_SZ * \"_\" + name + \".\") for name in names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndNfIJt059XZ",
    "outputId": "081bb96e-1972-432a-f698-04ba66bde71b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('emma.olivi', torch.Size([228146, 28]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttos(y_data[:10]), y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the `y_data` tensor to your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNLSmUpo58iE"
   },
   "outputs": [],
   "source": [
    "y_data = y_data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set should be shuffled before use for training. Use the `randperm` function to shuffle both the `X_data` and the `y_data` tensors along the 0th dimension.\n",
    "\n",
    "**NOTE:** Don't forget to set the seed using `manual_seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs08omJYoGPX",
    "outputId": "03114625-b672-450f-f340-dee6c58ba24f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.manual_seed(42)\n",
    "idx = pt.randperm(len(y_data))\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zKTYKwHo4_Q",
    "outputId": "851763b6-a627-4cb8-a321-7a64c429b19c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 4, 28]), torch.Size([228146, 28]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data, y_data = X_data[idx], y_data[idx]\n",
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data set is fairly large, let's use a 90%, 5%, 5% split for the training, validation, and test data sets respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmyhS0UEpQOs",
    "outputId": "dab9cbb8-a5d2-45df-acc8-ae6f7c27677f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([205331, 4, 28]),\n",
       " torch.Size([11407, 4, 28]),\n",
       " torch.Size([11408, 4, 28]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx, test_idx = int(len(X_data) * .9), int(len(X_data) * .95)\n",
    "X_train, y_train = X_data[:val_idx], y_data[:val_idx]\n",
    "X_val, y_val = X_data[val_idx:test_idx], y_data[val_idx:test_idx]\n",
    "X_test, y_test = X_data[test_idx:], y_data[test_idx:]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phYQ1OhIyssG"
   },
   "outputs": [],
   "source": [
    "class CharModel(pt.nn.Module):\n",
    "  def __init__(self, tokens_sz, ctx_sz, emb_sz, head_sz, n_heads, device):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.tok_emb = pt.nn.Embedding(tokens_sz, emb_sz, device = device)\n",
    "    self.pos_emb = pt.nn.Embedding(ctx_sz, emb_sz, device = device)\n",
    "    self.pos_idx = pt.arange(ctx_sz, device = device)\n",
    "    \n",
    "    self.kw = pt.nn.Linear(emb_sz, head_sz, device = device, bias = False)\n",
    "    self.qw = pt.nn.Linear(emb_sz, head_sz, device = device, bias = False)\n",
    "    self.vw = pt.nn.Linear(emb_sz, head_sz, device = device, bias = False)\n",
    "    self.mhsa = pt.nn.MultiheadAttention(head_sz, n_heads, batch_first = True, device = device)\n",
    "    self.mhsa_ln = pt.nn.LayerNorm(head_sz, device = device)\n",
    "    self.flatten = pt.nn.Flatten(1)\n",
    "    self.relu = pt.nn.ReLU()\n",
    "    self.mhsa_head = pt.nn.Linear(head_sz * ctx_sz, tokens_sz, device = device)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.tok_emb(x) + self.pos_emb(self.pos_idx)\n",
    "    q, k, v = self.qw(x), self.kw(x), self.vw(x)\n",
    "    x, _ = self.mhsa(q, k, v,  )\n",
    "    x = self.mhsa_ln(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.mhsa_head(x)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtnGlHhIzX5Y",
    "outputId": "f51d43a7-9729-4eba-d478-238de540b6c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharModel(\n",
       "  (tok_emb): Embedding(28, 32)\n",
       "  (pos_emb): Embedding(4, 32)\n",
       "  (kw): Linear(in_features=32, out_features=64, bias=False)\n",
       "  (qw): Linear(in_features=32, out_features=64, bias=False)\n",
       "  (vw): Linear(in_features=32, out_features=64, bias=False)\n",
       "  (mhsa): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (mhsa_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (relu): ReLU()\n",
       "  (mhsa_head): Linear(in_features=256, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMB_SZ = 32\n",
    "MHSA_HEAD_SZ = 64\n",
    "N_HEADS = 2\n",
    "nn = CharModel(len(tokens), CTX_SZ, EMB_SZ, MHSA_HEAD_SZ, N_HEADS, device)\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTV_Pb1Fzkyn",
    "outputId": "2e486725-b981-4505-9b84-4acac8f139e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = pt.stack([stot(\"_\" * CTX_SZ).argmax(-1).to(device)])\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVJde0gK50_f",
    "outputId": "83ad008f-47fb-4b04-93a6-bfc3b0f7875e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn(ctx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0pu6btx94hd",
    "outputId": "1f1d9723-64aa-4965-b2dc-c2e45cc85d23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = X_train.argmax(-1), y_train.argmax(-1)\n",
    "import copy\n",
    "model = copy.deepcopy(nn)\n",
    "optim = pt.optim.AdamW(model.parameters())\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28ehZRwLbfD_"
   },
   "outputs": [],
   "source": [
    "def generate(model, seed = 42, device = device, ctx_sz = 4, num_samples = 10, max_tokens = 16):\n",
    "  pt.manual_seed(seed)\n",
    "  samples = []  \n",
    "  ctx = pt.stack([stot(ctx_sz * \"_\").argmax(-1).to(device)])\n",
    "  for _ in range(num_samples):\n",
    "    sample = ctx.clone()\n",
    "    for _ in range(max_tokens):\n",
    "      logits = model(sample[:, -ctx_sz:])\n",
    "      probs = pt.nn.functional.softmax(logits, -1)\n",
    "      tok = pt.multinomial(probs, 1)\n",
    "      if tok.item() == 1:\n",
    "        break\n",
    "      sample = pt.cat([sample, tok], 1)\n",
    "\n",
    "    sample = dec(sample.squeeze().tolist()[ctx_sz:])\n",
    "    samples.append(sample)\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjYfqQr09nOm",
    "outputId": "d60f20f0-1ecd-4d8f-ece1-e0391fb3730d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 train loss 3.5386 val loss 3.5430\n",
      "uqhs,ydjxufqboodnojfa,fbmpphjlmhqhoghh,xbehaiwpbue_asxt,vvzupofylhhqvxhh,zpnhnmxtptbhboln,zr_vzrlyykugprtl,mplseyvksx_ukgbb,ucrsvcmypnqjddxt,qtxcsugychjgsosq\n",
      "\n",
      "epoch 100 train loss 2.2509 val loss 2.2490\n",
      "jehi,instulieon,noria,kare,jalyah,zahnielai,kauena,anon,nerfylelavahe,dahnantet\n",
      "\n",
      "epoch 200 train loss 2.1579 val loss 2.1654\n",
      "jehs,inshuilynn,nora,remon,jalyah,zahnielai,kaiena,anovennalylee,varez,nhnaxtathan\n",
      "\n",
      "epoch 300 train loss 2.1179 val loss 2.1332\n",
      "jehi,idhani,aonden,caredon,jamyah,zahnielai,kaielassir,zapry,lehav,rezan\n",
      "\n",
      "epoch 400 train loss 2.0943 val loss 2.1141\n",
      "jehi,idhani,amoden,caredon,jamyah,zahnielai,kaielassir,zapry,lehav,hezan\n",
      "\n",
      "epoch 500 train loss 2.0775 val loss 2.1025\n",
      "jehi,inshuit,onden,caredon,jamyah,zahnielai,kaielastir,zaedy,lehav,rezan\n",
      "\n",
      "epoch 600 train loss 2.0656 val loss 2.0945\n",
      "jehi,insey,kamoden,caredon,jamyah,zahnielai,kaielastir,zapto,leeg,lana\n",
      "\n",
      "epoch 700 train loss 2.0547 val loss 2.0859\n",
      "jehi,inshuir,onden,caredon,jamyah,zahnielai,kaielastion,neslylee,varen,nhamitat\n",
      "\n",
      "epoch 800 train loss 2.0468 val loss 2.0815\n",
      "jehi,inslyn,amoden,carman,rendy,holah,aelai,kaielastion,neslylee,varen\n",
      "\n",
      "epoch 900 train loss 2.0388 val loss 2.0753\n",
      "jehi,inslyn,amoden,carman,rendy,holah,aelai,kaielastion,neslylee,varez\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "for epoch in range(EPOCHS):\n",
    "  logits = model(X_batch)  \n",
    "  loss = pt.nn.functional.cross_entropy(logits, y_batch)\n",
    "  if epoch % 100 == 0:\n",
    "    with pt.no_grad():\n",
    "      val_loss = pt.nn.functional.cross_entropy(model(X_val.argmax(-1)), y_val.argmax(-1))\n",
    "      print(f\"epoch {epoch:2d} train loss {loss.item():.4f} val loss {val_loss.item():.4f}\")\n",
    "      samples = generate(model, device = device)\n",
    "      print(\",\".join(samples))\n",
    "      print()\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "  optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human preferences for reinforcement learning with human feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGnPA_KcNE0P",
    "outputId": "ec7c4ace-f2a5-4478-de9a-0377b4feab6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'liv', 'luz', 'sol', 'may']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "liked_names = [name for name in src.splitlines() if bool(re.match('^[^aeiou][aeiou][^aeiou]$', name))]\n",
    "liked_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avDTYfi1lGUn",
    "outputId": "73e4a6d1-c45a-4a91-b651-dd1009123535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['____joy.', '____liv.', '____luz.', '____sol.', '____may.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [CTX_SZ * \"_\" + name + \".\" for name in liked_names]\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-kZDIaZnHhe",
    "outputId": "355b230a-3c8f-4a1b-d424-567db47ced3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([936, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pt.cat([name_to_obs(name).argmax(-1) for name in names])\n",
    "obs = obs.to(device)\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-SChPNwoNPk",
    "outputId": "5d65ec83-adef-4139-b61f-a330bc3fc52b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([936])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = pt.cat([name_to_action(name).argmax(-1) for name in names])\n",
    "actions = actions.to(device)\n",
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaaksEIopFmb",
    "outputId": "66f5628b-16b3-4a3b-ec39-49667ca441fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7290, 0.8100, 0.9000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reward(name, gamma = .9):\n",
    "  idx = pt.arange(len(name) - 1, -1, -1).to(device)\n",
    "  return gamma ** idx\n",
    "\n",
    "reward(names[0][CTX_SZ:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6nO9k8ZEgPO",
    "outputId": "9c0f75ef-2243-416a-da91-2d5d9f859b54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7290, 0.8100, 0.9000, 1.0000, 0.7290, 0.8100, 0.9000, 1.0000, 0.7290,\n",
       "         0.8100], device='cuda:0'),\n",
       " tensor([11, 16, 26,  1, 13, 10, 23,  1, 13, 22], device='cuda:0'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = pt.cat([reward(name[CTX_SZ:]) for name in names])\n",
    "rewards[:10], actions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTRmeJXTGr8R"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "rl_model = copy.deepcopy(model)\n",
    "\n",
    "rl_optim = pt.optim.AdamW(rl_model.parameters())\n",
    "rl_optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Policy Gradient Reinforcement Learning\n",
    "* aka REINFORCE or vanilla policy gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6i_jTNvdIk17",
    "outputId": "0a7d201f-9b26-4dfa-9d8a-2c676274ab2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 loss=2.5757 net_new_names=10\n",
      "kaielastion,honah,aelai,inslyn,rendy,varez,jehi,neslylee,amoden,carman\n",
      "step =  1 loss=1.7851 net_new_names= 9\n",
      "dhik,wrodsi,fahna,buuri,neba,brinleigh,que,yuwanni,sair\n",
      "step =  2 loss=1.6210 net_new_names= 8\n",
      "dway,am,le,stan,dd,mad,na,saj\n",
      "step =  3 loss=1.5903 net_new_names= 7\n",
      "bres,jen,ma,din,ed,cor,al\n",
      "step =  4 loss=1.5442 net_new_names= 8\n",
      "jo,xyn,juss,jov,vih,lus,joh,le\n",
      "step =  5 loss=1.4966 net_new_names= 7\n",
      "tz,kil,gyn,k,am,blo,mux\n",
      "step =  6 loss=1.4621 net_new_names= 5\n",
      "vaz,ky,kex,pay,gi\n",
      "step =  7 loss=1.4353 net_new_names= 8\n",
      "d,lel,dal,nak,day,ney,let,n\n",
      "step =  8 loss=1.4096 net_new_names= 7\n",
      "jey,veg,xy,ced,azsi,za,dol\n",
      "step =  9 loss=1.3823 net_new_names= 8\n",
      "kad,laz,ric,tz,saz,run,nom,lez\n",
      "step = 10 loss=1.3604 net_new_names= 5\n",
      "kid,rax,jol,had,zem\n",
      "step = 11 loss=1.3456 net_new_names= 6\n",
      "las,kad,bed,zur,ceg,sten\n",
      "step = 12 loss=1.3354 net_new_names= 4\n",
      "x,jahd,kan,c\n",
      "step = 13 loss=1.3256 net_new_names= 6\n",
      "kah,jej,raw,ar,nav,ten\n",
      "step = 14 loss=1.3172 net_new_names= 6\n",
      "kem,zav,sel,mil,dow,gy\n",
      "step = 15 loss=1.3093 net_new_names= 4\n",
      "coc,gaj,bin,sil\n",
      "step = 16 loss=1.3002 net_new_names= 5\n",
      "teg,lir,yu,col,dem\n",
      "step = 17 loss=1.2909 net_new_names= 6\n",
      "im,duc,xim,ced,yon,til\n",
      "step = 18 loss=1.2823 net_new_names= 5\n",
      "haz,kan,jaz,dow,zuk\n",
      "step = 19 loss=1.2747 net_new_names= 7\n",
      "fim,men,yen,cac,ez,mug,ev\n"
     ]
    }
   ],
   "source": [
    "STEPS = 20\n",
    "for step in range(STEPS):\n",
    "  logits = rl_model(obs)\n",
    "  log_prob_dist = pt.nn.functional.log_softmax(logits, -1)\n",
    "  log_probs = log_prob_dist[pt.arange(len(actions)), actions]\n",
    "\n",
    "  #policy gradient\n",
    "  loss = -(rewards * log_probs).mean()\n",
    "  \n",
    "  with pt.no_grad():\n",
    "    names = generate(rl_model, device = device, seed = 42 + step)\n",
    "    new_names = set(set(names) - set(liked_names))\n",
    "    print(f\"step = {step:2d} loss={loss.item():.4f} net_new_names={len(new_names):2d}\")\n",
    "    print(\",\".join(new_names))\n",
    "\n",
    "  loss.backward()\n",
    "  rl_optim.step()\n",
    "  rl_optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximal Policy Optimization (PPO) Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TjGwmRymyF7"
   },
   "outputs": [],
   "source": [
    "rl_model = copy.deepcopy(model)\n",
    "ref_model = copy.deepcopy(model)\n",
    "\n",
    "rl_optim = pt.optim.Adam(rl_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wguyRbTOTm7",
    "outputId": "ca37399d-c270-40e0-e155-8fdcc89404cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 loss=2.5757 net_new_names=10\n",
      "kaielastion,honah,aelai,inslyn,rendy,varez,jehi,neslylee,amoden,carman\n",
      "step =  1 loss=1.7851 net_new_names= 9\n",
      "dhik,wrodsi,fahna,buuri,neba,brinleigh,que,yuwanni,sair\n",
      "step =  2 loss=1.6210 net_new_names= 8\n",
      "dway,am,le,stan,dd,mad,na,saj\n",
      "step =  3 loss=1.5903 net_new_names= 7\n",
      "bres,jen,ma,din,ed,cor,al\n",
      "step =  4 loss=1.5442 net_new_names= 8\n",
      "jo,xyn,juss,jov,vih,lus,joh,le\n",
      "step =  5 loss=1.4965 net_new_names= 7\n",
      "tz,kil,gyn,k,am,blo,mux\n",
      "step =  6 loss=1.4621 net_new_names= 5\n",
      "vaz,ky,kex,pay,gi\n",
      "step =  7 loss=1.4355 net_new_names= 8\n",
      "d,lel,dal,nak,day,ney,let,n\n",
      "step =  8 loss=1.4099 net_new_names= 8\n",
      "xy,laz,azsi,veg,dol,jey,ced,za\n",
      "step =  9 loss=1.3823 net_new_names= 8\n",
      "kad,laz,ric,tz,saz,run,nom,lez\n",
      "step = 10 loss=1.3604 net_new_names= 5\n",
      "kid,rax,jol,had,zem\n",
      "step = 11 loss=1.3456 net_new_names= 6\n",
      "las,kad,bed,zur,ceg,sten\n",
      "step = 12 loss=1.3353 net_new_names= 4\n",
      "x,jahd,kan,c\n",
      "step = 13 loss=1.3252 net_new_names= 6\n",
      "kah,jej,raw,ar,nav,ten\n",
      "step = 14 loss=1.3169 net_new_names= 6\n",
      "kem,zav,sel,mil,dow,gy\n",
      "step = 15 loss=1.3092 net_new_names= 4\n",
      "coc,gaj,bin,sil\n",
      "step = 16 loss=1.3002 net_new_names= 5\n",
      "teg,lir,yu,col,dem\n",
      "step = 17 loss=1.2907 net_new_names= 6\n",
      "im,duc,xim,ced,yon,til\n",
      "step = 18 loss=1.2822 net_new_names= 5\n",
      "haz,kan,jaz,dow,zuk\n",
      "step = 19 loss=1.2746 net_new_names= 7\n",
      "fim,men,yen,cac,ez,mig,ev\n"
     ]
    }
   ],
   "source": [
    "STEPS = 20\n",
    "for step in range(STEPS):\n",
    "  logits = rl_model(obs)\n",
    "  log_probs = pt.nn.functional.log_softmax(logits, -1)[pt.arange(len(actions)), actions]\n",
    "  with pt.no_grad():\n",
    "    ref_log_probs = pt.nn.functional.log_softmax(ref_model(obs), -1)[pt.arange(len(actions)), actions]\n",
    "  \n",
    "  ratio = log_probs - ref_log_probs\n",
    "  ratio = ratio.exp()\n",
    "\n",
    "  ppo_loss1 = rewards * ratio\n",
    "  ppo_loss2 = rewards * pt.clamp(ratio, .8, 1.2)\n",
    "\n",
    "  loss = -pt.min(ppo_loss1, ppo_loss2).mean()\n",
    "\n",
    "  #policy gradient\n",
    "  loss = -(rewards * log_probs).mean()\n",
    "  \n",
    "  with pt.no_grad():\n",
    "    names = generate(rl_model, device = device, seed = 42 + step)\n",
    "    new_names = set(set(names) - set(liked_names))\n",
    "    print(f\"step = {step:2d} loss={loss.item():.4f} net_new_names={len(new_names):2d}\")\n",
    "    print(\",\".join(new_names))\n",
    "\n",
    "  loss.backward()\n",
    "  rl_optim.step()\n",
    "  rl_optim.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
